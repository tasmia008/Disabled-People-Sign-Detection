{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T21:51:09.034955Z","iopub.status.busy":"2024-01-15T21:51:09.034318Z","iopub.status.idle":"2024-01-15T21:51:26.789911Z","shell.execute_reply":"2024-01-15T21:51:26.788854Z","shell.execute_reply.started":"2024-01-15T21:51:09.034923Z"},"papermill":{"duration":16.971538,"end_time":"2024-01-15T20:25:06.094958","exception":false,"start_time":"2024-01-15T20:24:49.12342","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Importing dependencies\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from tqdm.notebook import tqdm\n","\n","import tensorflow as tf\n","from tensorflow.keras import *\n","from tensorflow.keras.optimizers import AdamW\n","from tensorflow.keras.callbacks import Callback\n","import keras_cv\n","\n","\n","BATCH_SIZE = 4\n","GLOBAL_CLIPNORM = 10.0\n","\n","AUTO = tf.data.AUTOTUNE"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005837,"end_time":"2024-01-15T20:25:06.107151","exception":false,"start_time":"2024-01-15T20:25:06.101314","status":"completed"},"tags":[]},"source":["# <span style=\"color:#e74c3c;\"> </span> Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T20:25:06.120464Z","iopub.status.busy":"2024-01-15T20:25:06.11995Z","iopub.status.idle":"2024-01-15T20:25:06.130505Z","shell.execute_reply":"2024-01-15T20:25:06.129739Z"},"papermill":{"duration":0.01917,"end_time":"2024-01-15T20:25:06.132303","exception":false,"start_time":"2024-01-15T20:25:06.113133","status":"completed"},"tags":[]},"outputs":[],"source":["# a function for converting txt file to list\n","def parse_txt_annot(img_path, txt_path):\n","    img = cv2.imread(img_path)\n","    w = int(img.shape[0])\n","    h = int(img.shape[1])\n","\n","    file_label = open(txt_path, \"r\")\n","    lines = file_label.read().split('\\n')\n","    \n","    boxes = []\n","    classes = []\n","    \n","    for i in range(0, int(len(lines))):\n","        objbud=lines[i].split(' ')\n","        class_ = int(objbud[0])\n","        \n","        x1 = float(objbud[1])\n","        y1 = float(objbud[2])\n","        w1 = float(objbud[3])\n","        h1 = float(objbud[4])\n","        \n","        xmin = int((x1*w) - (w1*w)/2.0)\n","        ymin = int((y1*h) - (h1*h)/2.0)\n","        xmax = int((x1*w) + (w1*w)/2.0)\n","        ymax = int((y1*h) + (h1*h)/2.0)\n","    \n","        boxes.append([xmin ,ymin ,xmax ,ymax])\n","        classes.append(class_)\n","    \n","    return img_path, classes, boxes\n","\n","\n","# a function for creating file paths list \n","def create_paths_list(path):\n","    full_path = []\n","    images = sorted(os.listdir(path))\n","    \n","    for i in images:\n","        full_path.append(os.path.join(path, i))\n","        \n","    return full_path\n","\n","\n","class_ids = ['apart_parking', 'blackbox', 'disabled_parking', 'etc', 'highpass', 'navigator']\n","class_mapping = dict(zip(range(len(class_ids)), class_ids))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T20:25:06.145519Z","iopub.status.busy":"2024-01-15T20:25:06.144864Z","iopub.status.idle":"2024-01-15T20:25:06.151148Z","shell.execute_reply":"2024-01-15T20:25:06.150331Z"},"papermill":{"duration":0.014716,"end_time":"2024-01-15T20:25:06.15289","exception":false,"start_time":"2024-01-15T20:25:06.138174","status":"completed"},"tags":[]},"outputs":[],"source":["# a function for creating a dict format of files\n","def creating_files(img_files_paths, annot_files_paths):\n","    \n","    img_files = create_paths_list(img_files_paths)\n","    annot_files = create_paths_list(annot_files_paths)\n","    \n","    image_paths = []\n","    bbox = []\n","    classes = []\n","    \n","    for i in range(0,len(img_files)):\n","        image_path_, classes_, bbox_ = parse_txt_annot(img_files[i], annot_files[i])\n","        image_paths.append(image_path_)\n","        bbox.append(bbox_)\n","        classes.append(classes_)\n","        \n","    image_paths = tf.ragged.constant(image_paths)\n","    bbox = tf.ragged.constant(bbox)\n","    classes = tf.ragged.constant(classes)\n","    \n","    return image_paths, classes, bbox"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T20:25:06.165753Z","iopub.status.busy":"2024-01-15T20:25:06.165499Z","iopub.status.idle":"2024-01-15T20:25:22.647454Z","shell.execute_reply":"2024-01-15T20:25:22.646641Z"},"papermill":{"duration":16.490942,"end_time":"2024-01-15T20:25:22.649738","exception":false,"start_time":"2024-01-15T20:25:06.158796","status":"completed"},"tags":[]},"outputs":[],"source":["# applying functions\n","train_img_paths, train_classes, train_bboxes = creating_files('/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/train/images', \n","                                                              '/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/train/labels')\n","\n","valid_img_paths, valid_classes, valid_bboxes = creating_files('/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/valid/images', \n","                                                              '/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/valid/labels')\n","\n","test_img_paths, test_classes, test_bboxes = creating_files('/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/test/images', \n","                                                           '/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/test/labels')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005757,"end_time":"2024-01-15T20:25:22.661963","exception":false,"start_time":"2024-01-15T20:25:22.656206","status":"completed"},"tags":[]},"source":["# <span style=\"color:#e74c3c;\"> Creating </span> Datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T20:25:22.675481Z","iopub.status.busy":"2024-01-15T20:25:22.674645Z","iopub.status.idle":"2024-01-15T20:25:22.706623Z","shell.execute_reply":"2024-01-15T20:25:22.705901Z"},"papermill":{"duration":0.040825,"end_time":"2024-01-15T20:25:22.708643","exception":false,"start_time":"2024-01-15T20:25:22.667818","status":"completed"},"tags":[]},"outputs":[],"source":["# reading and resizing images\n","def img_preprocessing(img_path):\n","    img = tf.io.read_file(img_path)\n","    img = tf.image.decode_jpeg(img, channels = 3)\n","    img = tf.cast(img, tf.float32) \n","    \n","    return img\n","\n","\n","\n","resizing = keras_cv.layers.JitteredResize(\n","    target_size=(640, 640),\n","    scale_factor=(0.75, 1.3),\n","    bounding_box_format=\"xyxy\")\n","\n","# loading dataset\n","def load_ds(img_paths, classes, bbox):\n","    img = img_preprocessing(img_paths)\n","\n","    bounding_boxes = {\n","        \"classes\": tf.cast(classes, dtype=tf.float32),\n","        \"boxes\": bbox }\n","    \n","    return {\"images\": img, \"bounding_boxes\": bounding_boxes}\n","\n","def dict_to_tuple(inputs):\n","    return inputs[\"images\"], inputs[\"bounding_boxes\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T20:25:22.721656Z","iopub.status.busy":"2024-01-15T20:25:22.721376Z","iopub.status.idle":"2024-01-15T20:25:31.532197Z","shell.execute_reply":"2024-01-15T20:25:31.531219Z"},"papermill":{"duration":8.820011,"end_time":"2024-01-15T20:25:31.534604","exception":false,"start_time":"2024-01-15T20:25:22.714593","status":"completed"},"tags":[]},"outputs":[],"source":["# Creating dataset loaders and tf.datasets\n","train_loader = tf.data.Dataset.from_tensor_slices((train_img_paths, train_classes, train_bboxes))\n","train_dataset = (train_loader\n","                 .map(load_ds, num_parallel_calls = AUTO)\n","                 .shuffle(BATCH_SIZE*10)\n","                 .ragged_batch(BATCH_SIZE, drop_remainder = True)\n","                 .map(resizing, num_parallel_calls = AUTO)\n","                 .map(dict_to_tuple, num_parallel_calls = AUTO)\n","                 .prefetch(AUTO))\n","\n","\n","valid_loader = tf.data.Dataset.from_tensor_slices((valid_img_paths, valid_classes, valid_bboxes))\n","valid_dataset = (valid_loader\n","                 .map(load_ds, num_parallel_calls = AUTO)\n","                 .ragged_batch(BATCH_SIZE, drop_remainder = True)\n","                 .map(resizing, num_parallel_calls = AUTO)\n","                 .map(dict_to_tuple, num_parallel_calls = AUTO)\n","                 .prefetch(AUTO))\n","\n","\n","test_loader = tf.data.Dataset.from_tensor_slices((test_img_paths, test_classes, test_bboxes))\n","test_dataset = (test_loader\n","                .map(load_ds, num_parallel_calls = AUTO)\n","                .ragged_batch(BATCH_SIZE, drop_remainder = True)\n","                .map(resizing, num_parallel_calls = AUTO)\n","                .map(dict_to_tuple, num_parallel_calls = AUTO)\n","                .prefetch(AUTO))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T20:25:31.548364Z","iopub.status.busy":"2024-01-15T20:25:31.548072Z","iopub.status.idle":"2024-01-15T20:25:31.554035Z","shell.execute_reply":"2024-01-15T20:25:31.553291Z"},"papermill":{"duration":0.014929,"end_time":"2024-01-15T20:25:31.555835","exception":false,"start_time":"2024-01-15T20:25:31.540906","status":"completed"},"tags":[]},"outputs":[],"source":["# a function to visualize samples from a dataset\n","def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n","    inputs = next(iter(inputs.take(1)))\n","    images, bounding_boxes = inputs[0], inputs[1]\n","    \n","    keras_cv.visualization.plot_bounding_box_gallery(\n","        images,\n","        value_range=value_range,\n","        rows=rows,\n","        cols=cols,\n","        y_true=bounding_boxes,\n","        scale = 8,\n","        font_scale = 0.8,\n","        line_thickness=2,\n","        dpi = 100,\n","        bounding_box_format=bounding_box_format,\n","        class_mapping=class_mapping,\n","        true_color = (192, 57, 43))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T20:25:31.569539Z","iopub.status.busy":"2024-01-15T20:25:31.569268Z","iopub.status.idle":"2024-01-15T20:25:34.020878Z","shell.execute_reply":"2024-01-15T20:25:34.019961Z"},"papermill":{"duration":2.478806,"end_time":"2024-01-15T20:25:34.04058","exception":false,"start_time":"2024-01-15T20:25:31.561774","status":"completed"},"tags":[]},"outputs":[],"source":["# examples images and annotations from training daatset\n","visualize_dataset(train_dataset, bounding_box_format=\"xyxy\", value_range=(0, 255), rows=2, cols=2)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.023444,"end_time":"2024-01-15T20:25:34.087862","exception":false,"start_time":"2024-01-15T20:25:34.064418","status":"completed"},"tags":[]},"source":["# <span style=\"color:#e74c3c;\"> YOLO V8</span> Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T20:25:34.136094Z","iopub.status.busy":"2024-01-15T20:25:34.135735Z","iopub.status.idle":"2024-01-15T20:25:37.931196Z","shell.execute_reply":"2024-01-15T20:25:37.930205Z"},"papermill":{"duration":3.82238,"end_time":"2024-01-15T20:25:37.933623","exception":false,"start_time":"2024-01-15T20:25:34.111243","status":"completed"},"tags":[]},"outputs":[],"source":["# creating pre-trained model backbone with coco weights\n","backbone = keras_cv.models.YOLOV8Backbone.from_preset(\"yolo_v8_m_backbone_coco\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T20:25:37.98474Z","iopub.status.busy":"2024-01-15T20:25:37.984203Z","iopub.status.idle":"2024-01-15T20:25:39.611465Z","shell.execute_reply":"2024-01-15T20:25:39.610628Z"},"papermill":{"duration":1.65452,"end_time":"2024-01-15T20:25:39.613759","exception":false,"start_time":"2024-01-15T20:25:37.959239","status":"completed"},"tags":[]},"outputs":[],"source":["YOLOV8_model = keras_cv.models.YOLOV8Detector(num_classes=len(class_mapping),\n","                                              bounding_box_format=\"xyxy\",\n","                                              backbone=backbone, fpn_depth=1 )\n","\n","optimizer = AdamW(learning_rate=0.001, weight_decay=0.004, global_clipnorm = GLOBAL_CLIPNORM)\n","\n","YOLOV8_model.compile(optimizer = optimizer, classification_loss = 'binary_crossentropy', box_loss = 'ciou')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.023342,"end_time":"2024-01-15T20:25:39.721015","exception":false,"start_time":"2024-01-15T20:25:39.697673","status":"completed"},"tags":[]},"source":["# <span style=\"color:#e74c3c;\"> Training </span> "]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"collapsed":true,"execution":{"iopub.execute_input":"2024-01-15T20:25:39.769134Z","iopub.status.busy":"2024-01-15T20:25:39.768835Z","iopub.status.idle":"2024-01-15T21:43:37.412038Z","shell.execute_reply":"2024-01-15T21:43:37.410891Z"},"jupyter":{"outputs_hidden":true},"papermill":{"duration":4677.670273,"end_time":"2024-01-15T21:43:37.4148","exception":false,"start_time":"2024-01-15T20:25:39.744527","status":"completed"},"tags":[]},"outputs":[],"source":["hist = YOLOV8_model.fit(train_dataset, validation_data = valid_dataset,  epochs = 80 )"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":1.723815,"end_time":"2024-01-15T21:43:40.796493","exception":false,"start_time":"2024-01-15T21:43:39.072678","status":"completed"},"tags":[]},"source":["# <span style=\"color:#e74c3c;\"> Training </span> Results, Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T21:43:44.32166Z","iopub.status.busy":"2024-01-15T21:43:44.320724Z","iopub.status.idle":"2024-01-15T21:43:45.266653Z","shell.execute_reply":"2024-01-15T21:43:45.2656Z"},"papermill":{"duration":2.655893,"end_time":"2024-01-15T21:43:45.270145","exception":false,"start_time":"2024-01-15T21:43:42.614252","status":"completed"},"tags":[]},"outputs":[],"source":["fig, axs = plt.subplots(1,3, figsize = (18,5), dpi = 130)\n","\n","axs[0].grid(linestyle=\"dashdot\")\n","axs[0].set_title(\"Loss\")\n","axs[0].plot(hist.history['loss'][1:])\n","axs[0].plot(hist.history['val_loss'][1:])\n","axs[0].legend([\"train\", \"validataion\"])\n","\n","axs[1].grid(linestyle=\"dashdot\")\n","axs[1].set_title(\"Box Loss\")\n","axs[1].plot(hist.history['box_loss'])\n","axs[1].plot(hist.history['val_box_loss'])\n","axs[1].legend([\"train\",  \"validataion\"])\n","\n","axs[2].grid(linestyle=\"dashdot\")\n","axs[2].set_title(\"Class Loss\")\n","axs[2].plot(hist.history['class_loss'][1:])\n","axs[2].plot(hist.history['val_class_loss'][1:])\n","axs[2].legend([\"train\",  \"validataion\"])"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":1.727035,"end_time":"2024-01-15T21:43:48.783929","exception":false,"start_time":"2024-01-15T21:43:47.056894","status":"completed"},"tags":[]},"source":["# <span style=\"color:#e74c3c;\"> Test </span> Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T21:43:52.238376Z","iopub.status.busy":"2024-01-15T21:43:52.237979Z","iopub.status.idle":"2024-01-15T21:43:52.24489Z","shell.execute_reply":"2024-01-15T21:43:52.244041Z"},"papermill":{"duration":1.750878,"end_time":"2024-01-15T21:43:52.246747","exception":false,"start_time":"2024-01-15T21:43:50.495869","status":"completed"},"tags":[]},"outputs":[],"source":["def visualize_predict_detections(model, dataset, bounding_box_format):\n","    images, y_true = next(iter(dataset.take(1)))\n","        \n","    y_pred = model.predict(images)\n","    y_pred = keras_cv.bounding_box.to_ragged(y_pred)\n","    \n","    keras_cv.visualization.plot_bounding_box_gallery(\n","        images,\n","        value_range=(0, 255),\n","        bounding_box_format=bounding_box_format,\n","        y_true=y_true,\n","        y_pred=y_pred,\n","        true_color = (192, 57, 43),\n","        pred_color=(255, 235, 59),\n","        scale = 8,\n","        font_scale = 0.8,\n","        line_thickness=2,\n","        dpi = 100,\n","        rows=2,\n","        cols=2,\n","        show=True,\n","        class_mapping=class_mapping,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-15T21:43:55.675704Z","iopub.status.busy":"2024-01-15T21:43:55.674968Z","iopub.status.idle":"2024-01-15T21:44:02.836242Z","shell.execute_reply":"2024-01-15T21:44:02.835074Z"},"papermill":{"duration":8.862425,"end_time":"2024-01-15T21:44:02.859963","exception":false,"start_time":"2024-01-15T21:43:53.997538","status":"completed"},"tags":[]},"outputs":[],"source":["# red -> ground true\n","# yellow -> prediction\n","\n","visualize_predict_detections(YOLOV8_model, dataset = test_dataset, bounding_box_format=\"xyxy\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4305101,"sourceId":7403350,"sourceType":"datasetVersion"},{"modelInstanceId":4650,"sourceId":6107,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":4762.106118,"end_time":"2024-01-15T21:44:07.928033","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-15T20:24:45.821915","version":"2.4.0"}},"nbformat":4,"nbformat_minor":4}
